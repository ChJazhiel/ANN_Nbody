{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook implements Deep learning techniques for a particle-in-halo classification framework. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# workdirectory = '/home/jazhiel/ML_Notebooks/Cosmology_ML/'\n",
    "workdirectory = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/isidro/Documents/github/nnogada/\")\n",
    "from nnogada.Nnogada import Nnogada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import our dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.00000000e+00  2.72242898e+13  1.13894322e+13 ... -1.00000000e+00\n",
      " -1.00000000e+00 -1.00000000e+00]\n",
      "289964\n"
     ]
    }
   ],
   "source": [
    "data_dict = np.load(workdirectory+'OUTFILE1M.npz')\n",
    "test_flags  = data_dict['test_flags'] ## not important\n",
    "test_hosts  = data_dict['test_hosts'] ### somewhat relevant\n",
    "test_mass   = data_dict['test_mass'] ## important\n",
    "test_labels = data_dict['test_labels'] ## important\n",
    "test_input  = data_dict['test_input'] ## very important\n",
    "#test_snid   = dict_data['test_snid']\n",
    "#test_labels = dict_data['test_labels']\n",
    "print(test_mass) ## Here I want to check how is the halo mass matrix composed of, the -1 means the halo \n",
    "#is not in our range of 10^12-10^13 M_sun\n",
    "print(np.sum(test_labels)) ## Here I want to check how many label \"1\" do we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### here we create or 10 vector dataset, I wonder if by adding some other information the classification will be better\n",
    "### adding mass is not helpful, the classifier is perfect in that regard\n",
    "dr1 = pd.DataFrame(test_input[0], columns = ['dr1'])\n",
    "dr2 = pd.DataFrame(test_input[1], columns = ['dr2'])\n",
    "dr3 = pd.DataFrame(test_input[2], columns = ['dr3'])\n",
    "dr4 = pd.DataFrame(test_input[3], columns = ['dr4'])\n",
    "dr5 = pd.DataFrame(test_input[4], columns = ['dr5'])\n",
    "dr6 = pd.DataFrame(test_input[5], columns = ['dr6'])\n",
    "dr7 = pd.DataFrame(test_input[6], columns = ['dr7'])\n",
    "dr8 = pd.DataFrame(test_input[7], columns = ['dr8'])\n",
    "dr9 = pd.DataFrame(test_input[8], columns = ['dr9'])\n",
    "dr10 = pd.DataFrame(test_input[9], columns = ['dr10'])\n",
    "#mass = pd.DataFrame(test_mass, columns = ['Halo_Mass'])\n",
    "lbl = pd.DataFrame(test_labels, columns =['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select all features and create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dr1</th>\n",
       "      <th>dr2</th>\n",
       "      <th>dr3</th>\n",
       "      <th>dr4</th>\n",
       "      <th>dr5</th>\n",
       "      <th>dr6</th>\n",
       "      <th>dr7</th>\n",
       "      <th>dr8</th>\n",
       "      <th>dr9</th>\n",
       "      <th>dr10</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.209889</td>\n",
       "      <td>-0.187730</td>\n",
       "      <td>-0.169542</td>\n",
       "      <td>-0.155964</td>\n",
       "      <td>-0.100744</td>\n",
       "      <td>-0.049741</td>\n",
       "      <td>-0.011099</td>\n",
       "      <td>-0.010984</td>\n",
       "      <td>-0.002834</td>\n",
       "      <td>0.024089</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.364046</td>\n",
       "      <td>0.430008</td>\n",
       "      <td>0.453121</td>\n",
       "      <td>0.450021</td>\n",
       "      <td>0.374578</td>\n",
       "      <td>0.309706</td>\n",
       "      <td>0.240559</td>\n",
       "      <td>0.190503</td>\n",
       "      <td>0.174401</td>\n",
       "      <td>0.176335</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.311775</td>\n",
       "      <td>0.254511</td>\n",
       "      <td>0.227109</td>\n",
       "      <td>0.215286</td>\n",
       "      <td>0.148460</td>\n",
       "      <td>0.112097</td>\n",
       "      <td>0.090454</td>\n",
       "      <td>0.058546</td>\n",
       "      <td>0.035873</td>\n",
       "      <td>0.043613</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.033877</td>\n",
       "      <td>0.051836</td>\n",
       "      <td>0.065151</td>\n",
       "      <td>0.073930</td>\n",
       "      <td>0.100935</td>\n",
       "      <td>0.100271</td>\n",
       "      <td>0.094132</td>\n",
       "      <td>0.080007</td>\n",
       "      <td>0.059981</td>\n",
       "      <td>0.032160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.355428</td>\n",
       "      <td>-0.330448</td>\n",
       "      <td>-0.306125</td>\n",
       "      <td>-0.291701</td>\n",
       "      <td>-0.253399</td>\n",
       "      <td>-0.215256</td>\n",
       "      <td>-0.163749</td>\n",
       "      <td>-0.124680</td>\n",
       "      <td>-0.080408</td>\n",
       "      <td>-0.051999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>0.022223</td>\n",
       "      <td>0.034349</td>\n",
       "      <td>0.046298</td>\n",
       "      <td>0.047812</td>\n",
       "      <td>0.027945</td>\n",
       "      <td>0.018082</td>\n",
       "      <td>0.012005</td>\n",
       "      <td>0.015623</td>\n",
       "      <td>0.028762</td>\n",
       "      <td>0.036779</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>-0.178963</td>\n",
       "      <td>-0.188312</td>\n",
       "      <td>-0.189045</td>\n",
       "      <td>-0.187326</td>\n",
       "      <td>-0.182576</td>\n",
       "      <td>-0.170714</td>\n",
       "      <td>-0.155041</td>\n",
       "      <td>-0.143078</td>\n",
       "      <td>-0.136640</td>\n",
       "      <td>-0.120222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>-0.164632</td>\n",
       "      <td>-0.113120</td>\n",
       "      <td>-0.076089</td>\n",
       "      <td>-0.061724</td>\n",
       "      <td>0.009549</td>\n",
       "      <td>0.039809</td>\n",
       "      <td>0.057906</td>\n",
       "      <td>0.041327</td>\n",
       "      <td>0.010610</td>\n",
       "      <td>-0.020231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>-0.039698</td>\n",
       "      <td>0.063765</td>\n",
       "      <td>0.118363</td>\n",
       "      <td>0.140928</td>\n",
       "      <td>0.152761</td>\n",
       "      <td>0.125845</td>\n",
       "      <td>0.114529</td>\n",
       "      <td>0.113929</td>\n",
       "      <td>0.107155</td>\n",
       "      <td>0.098008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>0.153398</td>\n",
       "      <td>0.110778</td>\n",
       "      <td>0.080120</td>\n",
       "      <td>0.065841</td>\n",
       "      <td>0.043615</td>\n",
       "      <td>0.033935</td>\n",
       "      <td>0.012979</td>\n",
       "      <td>-0.002245</td>\n",
       "      <td>-0.008278</td>\n",
       "      <td>-0.021117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             dr1       dr2       dr3       dr4       dr5       dr6       dr7  \\\n",
       "0      -0.209889 -0.187730 -0.169542 -0.155964 -0.100744 -0.049741 -0.011099   \n",
       "1       0.364046  0.430008  0.453121  0.450021  0.374578  0.309706  0.240559   \n",
       "2       0.311775  0.254511  0.227109  0.215286  0.148460  0.112097  0.090454   \n",
       "3       0.033877  0.051836  0.065151  0.073930  0.100935  0.100271  0.094132   \n",
       "4      -0.355428 -0.330448 -0.306125 -0.291701 -0.253399 -0.215256 -0.163749   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "999995  0.022223  0.034349  0.046298  0.047812  0.027945  0.018082  0.012005   \n",
       "999996 -0.178963 -0.188312 -0.189045 -0.187326 -0.182576 -0.170714 -0.155041   \n",
       "999997 -0.164632 -0.113120 -0.076089 -0.061724  0.009549  0.039809  0.057906   \n",
       "999998 -0.039698  0.063765  0.118363  0.140928  0.152761  0.125845  0.114529   \n",
       "999999  0.153398  0.110778  0.080120  0.065841  0.043615  0.033935  0.012979   \n",
       "\n",
       "             dr8       dr9      dr10  labels  \n",
       "0      -0.010984 -0.002834  0.024089       0  \n",
       "1       0.190503  0.174401  0.176335       1  \n",
       "2       0.058546  0.035873  0.043613       1  \n",
       "3       0.080007  0.059981  0.032160       0  \n",
       "4      -0.124680 -0.080408 -0.051999       0  \n",
       "...          ...       ...       ...     ...  \n",
       "999995  0.015623  0.028762  0.036779       0  \n",
       "999996 -0.143078 -0.136640 -0.120222       0  \n",
       "999997  0.041327  0.010610 -0.020231       0  \n",
       "999998  0.113929  0.107155  0.098008       0  \n",
       "999999 -0.002245 -0.008278 -0.021117       0  \n",
       "\n",
       "[1000000 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([dr1, dr2, dr3, dr4, dr5, dr6, dr7, dr8, dr9, dr10, lbl], axis=1, ignore_index=False, sort=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we select a dataframe consisting of evenly separated labels\n",
    "\n",
    "(I'm not sure if selecting all particles will impact in a different result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sorting out the labels consisting in label '0' and label '1'\n",
    "## Then we sample them in order to not selecting them in a specific range or shape\n",
    "\n",
    "df_0 = df.sort_values('labels').head(710036).sample(289000)\n",
    "df_1 = df.sort_values('labels').tail(289964).sample(289000) \n",
    "df_1.labels.sum()\n",
    "df_r = pd.concat([df_0, df_1])\n",
    "\n",
    "\n",
    "randomize = np.random.permutation(len(df_r.values))\n",
    "data = df_r.values[randomize]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define a size for our traning dataset \n",
    "\n",
    "I think that for 500k + particles we can divide into train, test and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a size for your train set \n",
    "split = 0.8\n",
    "ntrain = int(split * len(data))\n",
    "indx = [ntrain]\n",
    "train_set, test_set = np.split(data, indx)\n",
    "\n",
    "split = 0.5\n",
    "ntrain = int(split * len(test_set))\n",
    "indx = [ntrain]\n",
    "validation_set, test_test = np.split(test_set, indx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select data, X for attributes, y for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set[:, :-1]\n",
    "y_train = train_set[:, -1]\n",
    "\n",
    "X_val = validation_set[:, :-1]\n",
    "y_val = validation_set[:, -1]\n",
    "\n",
    "X_test = test_set[:, :-1]\n",
    "y_test = test_set[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((462400, 10), (57800, 10), (115600, 10), (462400,), (57800,), (115600,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train), np.shape(X_val), np.shape(X_test), np.shape(y_train), np.shape(y_val), np.shape(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57800, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val = y_val.reshape(-1,1)\n",
    "np.shape(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(462400, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.reshape(-1,1)\n",
    "np.shape(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching hyperparameters with genetic algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "population_size = 10  # max of individuals per generation\n",
    "max_generations = 10   # number of generations\n",
    "gene_length = 4        # lenght of the gene, depends on how many hiperparameters are tested\n",
    "k = 1                  # num. of finalist individuals\n",
    "\n",
    "t = time.time()\n",
    "datos = []\n",
    "\n",
    "# Define the hyperparameters for the search\n",
    "hyperparams = {'deep': [3, 4], 'num_units': [100, 200], 'batch_size': [512, 1024]}\n",
    "\n",
    "# generate a Nnogada instance\n",
    "net_fit = Nnogada(hyp_to_find=hyperparams, X_train=X_train, Y_train=y_train, X_val=X_val, Y_val=y_val, regression=True)\n",
    "# Set the possible values of hyperparameters and not use the default values from hyperparameters.py\n",
    "net_fit.set_hyperparameters()\n",
    "\n",
    "# best solution\n",
    "best_population = net_fit.ga_with_elitism(population_size, max_generations, gene_length, k)\n",
    "print(best_population)\n",
    "print(\"Total elapsed time:\", (time.time()-t)/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the Confusion matrix \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### THIS CELL IS FOR CALCULATE THE CONFUSION MATRIX ####\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para scikit-learn: (samples,features)\n",
    "#test_input_T = test_input.T\n",
    "#X_train, X_test, y_train, y_test = train_test_split(test_input_T,test_labels,test_size=0.25,random_state=None)\n",
    "\n",
    "#ANN\n",
    "test1_model = models.Sequential()\n",
    "test1_model.add(layers.Dense(200,activation='tanh',input_shape=(10,)))\n",
    "test1_model.add(layers.Dense(200,activation='tanh'))\n",
    "test1_model.add(layers.Dense(200,activation='tanh'))\n",
    "#test1_model.add(layers.Dense(32,activation='relu'))\n",
    "#test1_model.add(layers.Dense(10,activation='relu'))\n",
    "test1_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "test1_model.compile(optimizer=optimizers.Adam(),#RMSprop(lr=0.001),\n",
    "                    loss=losses.binary_crossentropy,\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "\n",
    "test1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)]\n",
    "test1_model_history = test1_model.fit(X_train,\n",
    "                                      y_train,\n",
    "                                      epochs=200,\n",
    "                                      batch_size=512,\n",
    "                                      validation_data=(X_val,y_val),\n",
    "                                      verbose=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(11,4.5))    \n",
    "\n",
    "results_dict = test1_model_history.history\n",
    "epochs = range(1,len(results_dict['accuracy'])+1)\n",
    "\n",
    "#accuracy\n",
    "acc_values = results_dict['accuracy']\n",
    "val_acc_values = results_dict['val_accuracy']\n",
    "    \n",
    "axs[0].plot(epochs,acc_values,color='black',label='train',linewidth=1.5,linestyle='-')\n",
    "axs[0].plot(epochs,val_acc_values,color='red',label='test',linewidth=1.5,linestyle='-')\n",
    "axs[0].set_xlabel('epochs')\n",
    "minorLocatorX = AutoMinorLocator()\n",
    "axs[0].xaxis.set_minor_locator(minorLocatorX)\n",
    "axs[0].set_ylabel('accuracy')\n",
    "axs[0].set_ylim([0.5, 1.02])   \n",
    "minorLocatorY = AutoMinorLocator()\n",
    "axs[0].yaxis.set_minor_locator(minorLocatorY)\n",
    "axs[0].tick_params(which='major', length=6)\n",
    "axs[0].tick_params(which='minor', length=3, color='black')       \n",
    "axs[0].legend(loc='lower right')\n",
    "    \n",
    "#loss\n",
    "loss_values = results_dict['loss']\n",
    "val_loss_values = results_dict['val_loss']\n",
    "       \n",
    "axs[1].plot(epochs,loss_values,color='black',label='train',linewidth=1.5,linestyle='-')\n",
    "axs[1].plot(epochs,val_loss_values,color='red',label='test',linewidth=1.5,linestyle='-')\n",
    "axs[1].set_xlabel('epochs')\n",
    "minorLocatorX = AutoMinorLocator()\n",
    "axs[1].xaxis.set_minor_locator(minorLocatorX)   \n",
    "axs[1].set_ylabel('loss')\n",
    "minorLocatorY = AutoMinorLocator()\n",
    "axs[1].yaxis.set_minor_locator(minorLocatorY)\n",
    "axs[1].tick_params(which='major', length=6)\n",
    "axs[1].tick_params(which='minor', length=3, color='black')    \n",
    "axs[1].legend(loc='upper right')\n",
    "\n",
    "axs[0].set_title('Training and test accuracy after {} epochs: \\n {:.3f} (train), {:.3f} (validation)'\n",
    "                 .format(len(epochs),acc_values[-1],val_acc_values[-1]));\n",
    "\n",
    "axs[1].set_title('Training and test loss after {} epochs: \\n {:.3f} (train), {:.3f} (validation)'\n",
    "                 .format(len(epochs),loss_values[-1],val_loss_values[-1]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred2 =test1_model.predict(X_test)\n",
    "#####\n",
    "print('Traning and Testing on raw data, all features \\n');\n",
    "#### Model accuracy\n",
    "# print(\"Accuracy:\", metrics.accuracy_score(y_test, ypred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(ypred2), np.shape(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NEURAL NETWORK\")\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, ypred2.round()))\n",
    "print(\"F1:\", metrics.f1_score(y_test, ypred2.round()))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, ypred2.round()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, ypred2.round(), classes=['not in halo', 'in halo'])\n",
    "plt.title(\"NEURAL NETWORK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
