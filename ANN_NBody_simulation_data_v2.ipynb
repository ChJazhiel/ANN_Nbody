{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5685f17d",
   "metadata": {},
   "source": [
    "# This notebook will implement Deep learning techniques for a particle-in-halo classification framework. Refer to the original publicly notebook in [ChJazhiel notebook](https://github.com/ChJazhiel/ML_ICF/blob/master/RF_Particles_z23.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90d76f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# workdirectory = '/home/jazhiel/ML_Notebooks/Cosmology_ML/'\n",
    "workdirectory = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9463edce",
   "metadata": {},
   "source": [
    "## Import our dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8611873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.00000000e+00  2.72242898e+13  1.13894322e+13 ... -1.00000000e+00\n",
      " -1.00000000e+00 -1.00000000e+00]\n",
      "289964\n"
     ]
    }
   ],
   "source": [
    "data_dict = np.load(workdirectory + 'OUTFILE1M.npz') #np.load('/path/to/nbody/outfile.npz')\n",
    "test_flags  = data_dict['test_flags'] ## not important\n",
    "test_hosts  = data_dict['test_hosts'] ### somewhat relevant\n",
    "test_mass   = data_dict['test_mass'] ## important\n",
    "test_labels = data_dict['test_labels'] ## important\n",
    "test_input  = data_dict['test_input'] ## very important\n",
    "#test_snid   = dict_data['test_snid']\n",
    "#test_labels = dict_data['test_labels']\n",
    "print(test_mass) ## Here I want to check how is the halo mass matrix composed of, the -1 means the halo \n",
    "#is not in our range of 10^12-10^13 M_sun\n",
    "print(np.sum(test_labels)) ## Here I want to check how many label \"1\" do we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294f585b",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e5683e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### here we create or 10 vector dataset, I wonder if by adding some other information the classification will be better\n",
    "### adding mass is not helpful, the classifier is perfect in that regard\n",
    "dr1 = pd.DataFrame(test_input[0], columns = ['dr1'])\n",
    "dr2 = pd.DataFrame(test_input[1], columns = ['dr2'])\n",
    "dr3 = pd.DataFrame(test_input[2], columns = ['dr3'])\n",
    "dr4 = pd.DataFrame(test_input[3], columns = ['dr4'])\n",
    "dr5 = pd.DataFrame(test_input[4], columns = ['dr5'])\n",
    "dr6 = pd.DataFrame(test_input[5], columns = ['dr6'])\n",
    "dr7 = pd.DataFrame(test_input[6], columns = ['dr7'])\n",
    "dr8 = pd.DataFrame(test_input[7], columns = ['dr8'])\n",
    "dr9 = pd.DataFrame(test_input[8], columns = ['dr9'])\n",
    "dr10 = pd.DataFrame(test_input[9], columns = ['dr10'])\n",
    "#mass = pd.DataFrame(test_mass, columns = ['Halo_Mass'])\n",
    "lbl = pd.DataFrame(test_labels, columns =['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b35048",
   "metadata": {},
   "source": [
    "## Select all features and create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a8ae1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dr1</th>\n",
       "      <th>dr2</th>\n",
       "      <th>dr3</th>\n",
       "      <th>dr4</th>\n",
       "      <th>dr5</th>\n",
       "      <th>dr6</th>\n",
       "      <th>dr7</th>\n",
       "      <th>dr8</th>\n",
       "      <th>dr9</th>\n",
       "      <th>dr10</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.209889</td>\n",
       "      <td>-0.187730</td>\n",
       "      <td>-0.169542</td>\n",
       "      <td>-0.155964</td>\n",
       "      <td>-0.100744</td>\n",
       "      <td>-0.049741</td>\n",
       "      <td>-0.011099</td>\n",
       "      <td>-0.010984</td>\n",
       "      <td>-0.002834</td>\n",
       "      <td>0.024089</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.364046</td>\n",
       "      <td>0.430008</td>\n",
       "      <td>0.453121</td>\n",
       "      <td>0.450021</td>\n",
       "      <td>0.374578</td>\n",
       "      <td>0.309706</td>\n",
       "      <td>0.240559</td>\n",
       "      <td>0.190503</td>\n",
       "      <td>0.174401</td>\n",
       "      <td>0.176335</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.311775</td>\n",
       "      <td>0.254511</td>\n",
       "      <td>0.227109</td>\n",
       "      <td>0.215286</td>\n",
       "      <td>0.148460</td>\n",
       "      <td>0.112097</td>\n",
       "      <td>0.090454</td>\n",
       "      <td>0.058546</td>\n",
       "      <td>0.035873</td>\n",
       "      <td>0.043613</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.033877</td>\n",
       "      <td>0.051836</td>\n",
       "      <td>0.065151</td>\n",
       "      <td>0.073930</td>\n",
       "      <td>0.100935</td>\n",
       "      <td>0.100271</td>\n",
       "      <td>0.094132</td>\n",
       "      <td>0.080007</td>\n",
       "      <td>0.059981</td>\n",
       "      <td>0.032160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.355428</td>\n",
       "      <td>-0.330448</td>\n",
       "      <td>-0.306125</td>\n",
       "      <td>-0.291701</td>\n",
       "      <td>-0.253399</td>\n",
       "      <td>-0.215256</td>\n",
       "      <td>-0.163749</td>\n",
       "      <td>-0.124680</td>\n",
       "      <td>-0.080408</td>\n",
       "      <td>-0.051999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>0.022223</td>\n",
       "      <td>0.034349</td>\n",
       "      <td>0.046298</td>\n",
       "      <td>0.047812</td>\n",
       "      <td>0.027945</td>\n",
       "      <td>0.018082</td>\n",
       "      <td>0.012005</td>\n",
       "      <td>0.015623</td>\n",
       "      <td>0.028762</td>\n",
       "      <td>0.036779</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>-0.178963</td>\n",
       "      <td>-0.188312</td>\n",
       "      <td>-0.189045</td>\n",
       "      <td>-0.187326</td>\n",
       "      <td>-0.182576</td>\n",
       "      <td>-0.170714</td>\n",
       "      <td>-0.155041</td>\n",
       "      <td>-0.143078</td>\n",
       "      <td>-0.136640</td>\n",
       "      <td>-0.120222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>-0.164632</td>\n",
       "      <td>-0.113120</td>\n",
       "      <td>-0.076089</td>\n",
       "      <td>-0.061724</td>\n",
       "      <td>0.009549</td>\n",
       "      <td>0.039809</td>\n",
       "      <td>0.057906</td>\n",
       "      <td>0.041327</td>\n",
       "      <td>0.010610</td>\n",
       "      <td>-0.020231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>-0.039698</td>\n",
       "      <td>0.063765</td>\n",
       "      <td>0.118363</td>\n",
       "      <td>0.140928</td>\n",
       "      <td>0.152761</td>\n",
       "      <td>0.125845</td>\n",
       "      <td>0.114529</td>\n",
       "      <td>0.113929</td>\n",
       "      <td>0.107155</td>\n",
       "      <td>0.098008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>0.153398</td>\n",
       "      <td>0.110778</td>\n",
       "      <td>0.080120</td>\n",
       "      <td>0.065841</td>\n",
       "      <td>0.043615</td>\n",
       "      <td>0.033935</td>\n",
       "      <td>0.012979</td>\n",
       "      <td>-0.002245</td>\n",
       "      <td>-0.008278</td>\n",
       "      <td>-0.021117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             dr1       dr2       dr3       dr4       dr5       dr6       dr7  \\\n",
       "0      -0.209889 -0.187730 -0.169542 -0.155964 -0.100744 -0.049741 -0.011099   \n",
       "1       0.364046  0.430008  0.453121  0.450021  0.374578  0.309706  0.240559   \n",
       "2       0.311775  0.254511  0.227109  0.215286  0.148460  0.112097  0.090454   \n",
       "3       0.033877  0.051836  0.065151  0.073930  0.100935  0.100271  0.094132   \n",
       "4      -0.355428 -0.330448 -0.306125 -0.291701 -0.253399 -0.215256 -0.163749   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "999995  0.022223  0.034349  0.046298  0.047812  0.027945  0.018082  0.012005   \n",
       "999996 -0.178963 -0.188312 -0.189045 -0.187326 -0.182576 -0.170714 -0.155041   \n",
       "999997 -0.164632 -0.113120 -0.076089 -0.061724  0.009549  0.039809  0.057906   \n",
       "999998 -0.039698  0.063765  0.118363  0.140928  0.152761  0.125845  0.114529   \n",
       "999999  0.153398  0.110778  0.080120  0.065841  0.043615  0.033935  0.012979   \n",
       "\n",
       "             dr8       dr9      dr10  labels  \n",
       "0      -0.010984 -0.002834  0.024089       0  \n",
       "1       0.190503  0.174401  0.176335       1  \n",
       "2       0.058546  0.035873  0.043613       1  \n",
       "3       0.080007  0.059981  0.032160       0  \n",
       "4      -0.124680 -0.080408 -0.051999       0  \n",
       "...          ...       ...       ...     ...  \n",
       "999995  0.015623  0.028762  0.036779       0  \n",
       "999996 -0.143078 -0.136640 -0.120222       0  \n",
       "999997  0.041327  0.010610 -0.020231       0  \n",
       "999998  0.113929  0.107155  0.098008       0  \n",
       "999999 -0.002245 -0.008278 -0.021117       0  \n",
       "\n",
       "[1000000 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([dr1, dr2, dr3, dr4, dr5, dr6, dr7, dr8, dr9, dr10, lbl], axis=1, ignore_index=False, sort=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ebe86a",
   "metadata": {},
   "source": [
    "## Here we select a dataframe consisting of evenly separated labels\n",
    "\n",
    "(I'm not sure if selecting all particles will impact in a different result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89d16555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dr1</th>\n",
       "      <th>dr2</th>\n",
       "      <th>dr3</th>\n",
       "      <th>dr4</th>\n",
       "      <th>dr5</th>\n",
       "      <th>dr6</th>\n",
       "      <th>dr7</th>\n",
       "      <th>dr8</th>\n",
       "      <th>dr9</th>\n",
       "      <th>dr10</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114074</th>\n",
       "      <td>0.026622</td>\n",
       "      <td>-0.006134</td>\n",
       "      <td>-0.006339</td>\n",
       "      <td>-0.002562</td>\n",
       "      <td>0.027857</td>\n",
       "      <td>0.060640</td>\n",
       "      <td>0.087173</td>\n",
       "      <td>0.114187</td>\n",
       "      <td>0.121830</td>\n",
       "      <td>0.102355</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247021</th>\n",
       "      <td>0.076285</td>\n",
       "      <td>0.081491</td>\n",
       "      <td>0.101477</td>\n",
       "      <td>0.117110</td>\n",
       "      <td>0.097762</td>\n",
       "      <td>0.095314</td>\n",
       "      <td>0.085185</td>\n",
       "      <td>0.068890</td>\n",
       "      <td>0.058849</td>\n",
       "      <td>0.062756</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925244</th>\n",
       "      <td>0.203805</td>\n",
       "      <td>0.256781</td>\n",
       "      <td>0.253981</td>\n",
       "      <td>0.238800</td>\n",
       "      <td>0.228309</td>\n",
       "      <td>0.225982</td>\n",
       "      <td>0.211441</td>\n",
       "      <td>0.174322</td>\n",
       "      <td>0.150403</td>\n",
       "      <td>0.145066</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567886</th>\n",
       "      <td>0.094756</td>\n",
       "      <td>0.050047</td>\n",
       "      <td>0.024114</td>\n",
       "      <td>0.012384</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>-0.003903</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.007552</td>\n",
       "      <td>0.010601</td>\n",
       "      <td>0.016956</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967527</th>\n",
       "      <td>-0.012243</td>\n",
       "      <td>0.034301</td>\n",
       "      <td>0.040747</td>\n",
       "      <td>0.041883</td>\n",
       "      <td>0.079139</td>\n",
       "      <td>0.103540</td>\n",
       "      <td>0.121837</td>\n",
       "      <td>0.147844</td>\n",
       "      <td>0.150164</td>\n",
       "      <td>0.116473</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219424</th>\n",
       "      <td>0.156575</td>\n",
       "      <td>0.139391</td>\n",
       "      <td>0.129394</td>\n",
       "      <td>0.123158</td>\n",
       "      <td>0.149332</td>\n",
       "      <td>0.168104</td>\n",
       "      <td>0.169997</td>\n",
       "      <td>0.149111</td>\n",
       "      <td>0.146129</td>\n",
       "      <td>0.139427</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518270</th>\n",
       "      <td>0.348880</td>\n",
       "      <td>0.323346</td>\n",
       "      <td>0.287654</td>\n",
       "      <td>0.257516</td>\n",
       "      <td>0.229198</td>\n",
       "      <td>0.180555</td>\n",
       "      <td>0.128919</td>\n",
       "      <td>0.095656</td>\n",
       "      <td>0.059576</td>\n",
       "      <td>0.037967</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376075</th>\n",
       "      <td>-0.310457</td>\n",
       "      <td>-0.249178</td>\n",
       "      <td>-0.207620</td>\n",
       "      <td>-0.188395</td>\n",
       "      <td>-0.136709</td>\n",
       "      <td>-0.121262</td>\n",
       "      <td>-0.108247</td>\n",
       "      <td>-0.107783</td>\n",
       "      <td>-0.110706</td>\n",
       "      <td>-0.123596</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489841</th>\n",
       "      <td>-0.001529</td>\n",
       "      <td>0.046879</td>\n",
       "      <td>0.073977</td>\n",
       "      <td>0.082090</td>\n",
       "      <td>0.084862</td>\n",
       "      <td>0.070727</td>\n",
       "      <td>0.042188</td>\n",
       "      <td>0.021427</td>\n",
       "      <td>0.032157</td>\n",
       "      <td>0.049011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140224</th>\n",
       "      <td>-0.312853</td>\n",
       "      <td>-0.290834</td>\n",
       "      <td>-0.284779</td>\n",
       "      <td>-0.285317</td>\n",
       "      <td>-0.245500</td>\n",
       "      <td>-0.226414</td>\n",
       "      <td>-0.191656</td>\n",
       "      <td>-0.133008</td>\n",
       "      <td>-0.073376</td>\n",
       "      <td>-0.049259</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>578000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             dr1       dr2       dr3       dr4       dr5       dr6       dr7  \\\n",
       "114074  0.026622 -0.006134 -0.006339 -0.002562  0.027857  0.060640  0.087173   \n",
       "247021  0.076285  0.081491  0.101477  0.117110  0.097762  0.095314  0.085185   \n",
       "925244  0.203805  0.256781  0.253981  0.238800  0.228309  0.225982  0.211441   \n",
       "567886  0.094756  0.050047  0.024114  0.012384  0.005600 -0.003903  0.000206   \n",
       "967527 -0.012243  0.034301  0.040747  0.041883  0.079139  0.103540  0.121837   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "219424  0.156575  0.139391  0.129394  0.123158  0.149332  0.168104  0.169997   \n",
       "518270  0.348880  0.323346  0.287654  0.257516  0.229198  0.180555  0.128919   \n",
       "376075 -0.310457 -0.249178 -0.207620 -0.188395 -0.136709 -0.121262 -0.108247   \n",
       "489841 -0.001529  0.046879  0.073977  0.082090  0.084862  0.070727  0.042188   \n",
       "140224 -0.312853 -0.290834 -0.284779 -0.285317 -0.245500 -0.226414 -0.191656   \n",
       "\n",
       "             dr8       dr9      dr10  labels  \n",
       "114074  0.114187  0.121830  0.102355       0  \n",
       "247021  0.068890  0.058849  0.062756       0  \n",
       "925244  0.174322  0.150403  0.145066       1  \n",
       "567886  0.007552  0.010601  0.016956       0  \n",
       "967527  0.147844  0.150164  0.116473       0  \n",
       "...          ...       ...       ...     ...  \n",
       "219424  0.149111  0.146129  0.139427       1  \n",
       "518270  0.095656  0.059576  0.037967       1  \n",
       "376075 -0.107783 -0.110706 -0.123596       0  \n",
       "489841  0.021427  0.032157  0.049011       0  \n",
       "140224 -0.133008 -0.073376 -0.049259       0  \n",
       "\n",
       "[578000 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sorting out the labels consisting in label '0' and label '1'\n",
    "## Then we sample them in order to not selecting them in a specific range or shape\n",
    "\n",
    "df_0 = df.sort_values('labels').head(710036).sample(289000)\n",
    "df_1 = df.sort_values('labels').tail(289964).sample(289000) \n",
    "df_1.labels.sum()\n",
    "df_r = pd.concat([df_0, df_1])\n",
    "#df_scaled = scaler.fit_transform(df_r.drop(['labels'], axis = 1))  \n",
    "#df_copy1 = pd.DataFrame(df_scaled, columns=['dr1', 'dr2', 'dr3', 'dr4', 'dr5', 'dr6', 'dr7', 'dr8', 'dr9', 'dr10'])\n",
    "\n",
    "shuffle_df = df_r.sample(frac = 1.0)\n",
    "#shuffle_df.insert(10, \"Model\", ['LC','SF']*14300, True)\n",
    "shuffle_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6945ae",
   "metadata": {},
   "source": [
    "## define a size for our traning dataset \n",
    "\n",
    "I think that for 500k + particles we can divide into train, test and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53e3070e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dr1</th>\n",
       "      <th>dr2</th>\n",
       "      <th>dr3</th>\n",
       "      <th>dr4</th>\n",
       "      <th>dr5</th>\n",
       "      <th>dr6</th>\n",
       "      <th>dr7</th>\n",
       "      <th>dr8</th>\n",
       "      <th>dr9</th>\n",
       "      <th>dr10</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114074</th>\n",
       "      <td>0.026622</td>\n",
       "      <td>-0.006134</td>\n",
       "      <td>-0.006339</td>\n",
       "      <td>-0.002562</td>\n",
       "      <td>0.027857</td>\n",
       "      <td>0.060640</td>\n",
       "      <td>0.087173</td>\n",
       "      <td>0.114187</td>\n",
       "      <td>0.121830</td>\n",
       "      <td>0.102355</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247021</th>\n",
       "      <td>0.076285</td>\n",
       "      <td>0.081491</td>\n",
       "      <td>0.101477</td>\n",
       "      <td>0.117110</td>\n",
       "      <td>0.097762</td>\n",
       "      <td>0.095314</td>\n",
       "      <td>0.085185</td>\n",
       "      <td>0.068890</td>\n",
       "      <td>0.058849</td>\n",
       "      <td>0.062756</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925244</th>\n",
       "      <td>0.203805</td>\n",
       "      <td>0.256781</td>\n",
       "      <td>0.253981</td>\n",
       "      <td>0.238800</td>\n",
       "      <td>0.228309</td>\n",
       "      <td>0.225982</td>\n",
       "      <td>0.211441</td>\n",
       "      <td>0.174322</td>\n",
       "      <td>0.150403</td>\n",
       "      <td>0.145066</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567886</th>\n",
       "      <td>0.094756</td>\n",
       "      <td>0.050047</td>\n",
       "      <td>0.024114</td>\n",
       "      <td>0.012384</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>-0.003903</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.007552</td>\n",
       "      <td>0.010601</td>\n",
       "      <td>0.016956</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967527</th>\n",
       "      <td>-0.012243</td>\n",
       "      <td>0.034301</td>\n",
       "      <td>0.040747</td>\n",
       "      <td>0.041883</td>\n",
       "      <td>0.079139</td>\n",
       "      <td>0.103540</td>\n",
       "      <td>0.121837</td>\n",
       "      <td>0.147844</td>\n",
       "      <td>0.150164</td>\n",
       "      <td>0.116473</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729558</th>\n",
       "      <td>0.212113</td>\n",
       "      <td>0.183576</td>\n",
       "      <td>0.167638</td>\n",
       "      <td>0.161483</td>\n",
       "      <td>0.139855</td>\n",
       "      <td>0.120183</td>\n",
       "      <td>0.095670</td>\n",
       "      <td>0.093532</td>\n",
       "      <td>0.110854</td>\n",
       "      <td>0.108310</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388827</th>\n",
       "      <td>-0.088783</td>\n",
       "      <td>-0.030785</td>\n",
       "      <td>0.013404</td>\n",
       "      <td>0.033890</td>\n",
       "      <td>0.080209</td>\n",
       "      <td>0.071070</td>\n",
       "      <td>0.062266</td>\n",
       "      <td>0.058827</td>\n",
       "      <td>0.036604</td>\n",
       "      <td>0.027457</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377480</th>\n",
       "      <td>0.283100</td>\n",
       "      <td>0.249064</td>\n",
       "      <td>0.261652</td>\n",
       "      <td>0.262266</td>\n",
       "      <td>0.206714</td>\n",
       "      <td>0.177706</td>\n",
       "      <td>0.136981</td>\n",
       "      <td>0.129759</td>\n",
       "      <td>0.123402</td>\n",
       "      <td>0.094036</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345680</th>\n",
       "      <td>0.333194</td>\n",
       "      <td>0.267164</td>\n",
       "      <td>0.215277</td>\n",
       "      <td>0.184976</td>\n",
       "      <td>0.103820</td>\n",
       "      <td>0.063887</td>\n",
       "      <td>0.023875</td>\n",
       "      <td>-0.015216</td>\n",
       "      <td>-0.037427</td>\n",
       "      <td>-0.046541</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941095</th>\n",
       "      <td>0.167581</td>\n",
       "      <td>0.119824</td>\n",
       "      <td>0.084957</td>\n",
       "      <td>0.069362</td>\n",
       "      <td>0.056968</td>\n",
       "      <td>0.067177</td>\n",
       "      <td>0.069322</td>\n",
       "      <td>0.068496</td>\n",
       "      <td>0.074226</td>\n",
       "      <td>0.054412</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>462400 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             dr1       dr2       dr3       dr4       dr5       dr6       dr7  \\\n",
       "114074  0.026622 -0.006134 -0.006339 -0.002562  0.027857  0.060640  0.087173   \n",
       "247021  0.076285  0.081491  0.101477  0.117110  0.097762  0.095314  0.085185   \n",
       "925244  0.203805  0.256781  0.253981  0.238800  0.228309  0.225982  0.211441   \n",
       "567886  0.094756  0.050047  0.024114  0.012384  0.005600 -0.003903  0.000206   \n",
       "967527 -0.012243  0.034301  0.040747  0.041883  0.079139  0.103540  0.121837   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "729558  0.212113  0.183576  0.167638  0.161483  0.139855  0.120183  0.095670   \n",
       "388827 -0.088783 -0.030785  0.013404  0.033890  0.080209  0.071070  0.062266   \n",
       "377480  0.283100  0.249064  0.261652  0.262266  0.206714  0.177706  0.136981   \n",
       "345680  0.333194  0.267164  0.215277  0.184976  0.103820  0.063887  0.023875   \n",
       "941095  0.167581  0.119824  0.084957  0.069362  0.056968  0.067177  0.069322   \n",
       "\n",
       "             dr8       dr9      dr10  labels  \n",
       "114074  0.114187  0.121830  0.102355       0  \n",
       "247021  0.068890  0.058849  0.062756       0  \n",
       "925244  0.174322  0.150403  0.145066       1  \n",
       "567886  0.007552  0.010601  0.016956       0  \n",
       "967527  0.147844  0.150164  0.116473       0  \n",
       "...          ...       ...       ...     ...  \n",
       "729558  0.093532  0.110854  0.108310       0  \n",
       "388827  0.058827  0.036604  0.027457       1  \n",
       "377480  0.129759  0.123402  0.094036       1  \n",
       "345680 -0.015216 -0.037427 -0.046541       1  \n",
       "941095  0.068496  0.074226  0.054412       0  \n",
       "\n",
       "[462400 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a size for your train set \n",
    "train_size = int(0.8 * len(df_r))\n",
    "\n",
    "# Split your dataset \n",
    "train_set = shuffle_df[:train_size]\n",
    "test_set = shuffle_df[train_size:]\n",
    "\n",
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea37a45e",
   "metadata": {},
   "source": [
    "## Select data, X for attributes, y for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcff1978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(462400, 10)\n"
     ]
    }
   ],
   "source": [
    "X = shuffle_df.drop(['labels'], axis = 1)\n",
    "ylabels = shuffle_df.labels\n",
    "#ymodel = shuffle_df.Model\n",
    "#ymodel = copy1.Model\n",
    "X_train = train_set.drop(['labels'], axis = 1)\n",
    "X_test = test_set.drop(['labels'], axis= 1)\n",
    "y_trainl = train_set.labels\n",
    "y_testl = test_set.labels\n",
    "#y_trainM = train_set.Model\n",
    "#y_testM = test_set.Model\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4b80d4",
   "metadata": {},
   "source": [
    "## For the Confusion matrix \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee69ca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### THIS CELL IS FOR CALCULATE THE CONFUSION MATRIX ####\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "    \n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4b75da",
   "metadata": {},
   "source": [
    "## Random forest with sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75046e03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning and Testing on raw data, all features \n",
      "\n",
      "Accuracy: 0.7857871972318339\n",
      "Random Forest accuracy for the 0 score: 0.78\n",
      "Random Forest accuracy for the 1 score: 0.78\n",
      "Random Forest accuracy for the 2 score: 0.79\n",
      "Random Forest Accuracy: 0.78 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "rf=RandomForestClassifier(n_estimators=100, max_depth=8, n_jobs=-1,\n",
    "                          criterion = 'entropy', class_weight='balanced')\n",
    "\n",
    "## n_jobs = -1 tells my computer to use all its cores, I have only 2, so it runs on 2 cores\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "rf.fit(X_train,y_trainl)\n",
    "\n",
    "ypred = rf.predict(X_test)\n",
    "#####\n",
    "\n",
    "print('Traning and Testing on raw data, all features \\n');\n",
    "#### Model accuracy\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_testl, ypred))\n",
    "\n",
    "for i, score_forest in enumerate(cross_val_score(rf, X, ylabels, cv = 3)):\n",
    "    print('Random Forest accuracy for the %d score: %0.2f' % (i, score_forest))\n",
    "score_forest=cross_val_score(rf, X, ylabels, cv=3)\n",
    "#score_tree\n",
    "cv_scores = []\n",
    "print(\"Random Forest Accuracy: %0.2f (+/- %0.2f)\" % (score_forest.mean(), score_forest.std() * 2 ))\n",
    "cv_score = score_forest.mean()\n",
    "cv_scores.append(cv_score)\n",
    "\n",
    "### We perform a cross validation score to see how accurate our decision tree is by \n",
    "### splitting the dataset into 10 folds for training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c5ab21",
   "metadata": {},
   "source": [
    "## Perceptron with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f21163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 100)               1100      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 11,301\n",
      "Trainable params: 11,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 22:29:35.321030: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14450/14450 [==============================] - 9s 629us/step - loss: 0.4676 - accuracy: 0.7793 - val_loss: 0.4592 - val_accuracy: 0.7828\n",
      "Epoch 2/50\n",
      "14450/14450 [==============================] - 9s 613us/step - loss: 0.4601 - accuracy: 0.7815 - val_loss: 0.4579 - val_accuracy: 0.7838\n",
      "Epoch 3/50\n",
      "14450/14450 [==============================] - 9s 611us/step - loss: 0.4594 - accuracy: 0.7820 - val_loss: 0.4580 - val_accuracy: 0.7830\n",
      "Epoch 4/50\n",
      "14450/14450 [==============================] - 9s 606us/step - loss: 0.4591 - accuracy: 0.7818 - val_loss: 0.4575 - val_accuracy: 0.7835\n",
      "Epoch 5/50\n",
      "14450/14450 [==============================] - 9s 606us/step - loss: 0.4588 - accuracy: 0.7820 - val_loss: 0.4572 - val_accuracy: 0.7834\n",
      "Epoch 6/50\n",
      "14450/14450 [==============================] - 9s 607us/step - loss: 0.4587 - accuracy: 0.7822 - val_loss: 0.4569 - val_accuracy: 0.7837\n",
      "Epoch 7/50\n",
      "14450/14450 [==============================] - 9s 610us/step - loss: 0.4585 - accuracy: 0.7823 - val_loss: 0.4565 - val_accuracy: 0.7837\n",
      "Epoch 8/50\n",
      "14450/14450 [==============================] - 9s 600us/step - loss: 0.4584 - accuracy: 0.7823 - val_loss: 0.4574 - val_accuracy: 0.7833\n",
      "Epoch 9/50\n",
      "14450/14450 [==============================] - 9s 608us/step - loss: 0.4583 - accuracy: 0.7823 - val_loss: 0.4564 - val_accuracy: 0.7838\n",
      "Epoch 10/50\n",
      "14450/14450 [==============================] - 9s 615us/step - loss: 0.4582 - accuracy: 0.7824 - val_loss: 0.4563 - val_accuracy: 0.7838\n",
      "Epoch 11/50\n",
      "14450/14450 [==============================] - 9s 608us/step - loss: 0.4581 - accuracy: 0.7825 - val_loss: 0.4563 - val_accuracy: 0.7835\n",
      "Epoch 12/50\n",
      "14450/14450 [==============================] - 9s 608us/step - loss: 0.4580 - accuracy: 0.7824 - val_loss: 0.4562 - val_accuracy: 0.7840\n",
      "Epoch 13/50\n",
      "14450/14450 [==============================] - 9s 624us/step - loss: 0.4580 - accuracy: 0.7825 - val_loss: 0.4559 - val_accuracy: 0.7843\n",
      "Epoch 14/50\n",
      "14450/14450 [==============================] - 9s 618us/step - loss: 0.4579 - accuracy: 0.7824 - val_loss: 0.4565 - val_accuracy: 0.7836\n",
      "Epoch 15/50\n",
      "14450/14450 [==============================] - 9s 608us/step - loss: 0.4578 - accuracy: 0.7825 - val_loss: 0.4561 - val_accuracy: 0.7840\n",
      "Epoch 16/50\n",
      "14450/14450 [==============================] - 9s 611us/step - loss: 0.4578 - accuracy: 0.7826 - val_loss: 0.4557 - val_accuracy: 0.7841\n",
      "Epoch 17/50\n",
      "14450/14450 [==============================] - 9s 614us/step - loss: 0.4577 - accuracy: 0.7824 - val_loss: 0.4560 - val_accuracy: 0.7836\n",
      "Epoch 18/50\n",
      "14450/14450 [==============================] - 9s 625us/step - loss: 0.4576 - accuracy: 0.7827 - val_loss: 0.4556 - val_accuracy: 0.7839\n",
      "Epoch 19/50\n",
      "14450/14450 [==============================] - 10s 673us/step - loss: 0.4576 - accuracy: 0.7826 - val_loss: 0.4557 - val_accuracy: 0.7841\n",
      "Epoch 20/50\n",
      "14450/14450 [==============================] - 9s 620us/step - loss: 0.4574 - accuracy: 0.7826 - val_loss: 0.4566 - val_accuracy: 0.7835\n",
      "Epoch 21/50\n",
      "14450/14450 [==============================] - 9s 620us/step - loss: 0.4575 - accuracy: 0.7825 - val_loss: 0.4555 - val_accuracy: 0.7842\n",
      "Epoch 22/50\n",
      "14450/14450 [==============================] - 9s 611us/step - loss: 0.4574 - accuracy: 0.7830 - val_loss: 0.4556 - val_accuracy: 0.7842\n",
      "Epoch 23/50\n",
      "14450/14450 [==============================] - 9s 612us/step - loss: 0.4573 - accuracy: 0.7828 - val_loss: 0.4556 - val_accuracy: 0.7839\n",
      "Epoch 24/50\n",
      "14450/14450 [==============================] - 9s 613us/step - loss: 0.4572 - accuracy: 0.7827 - val_loss: 0.4553 - val_accuracy: 0.7844\n",
      "Epoch 25/50\n",
      "14450/14450 [==============================] - 9s 608us/step - loss: 0.4572 - accuracy: 0.7831 - val_loss: 0.4554 - val_accuracy: 0.7846\n",
      "Epoch 26/50\n",
      "14450/14450 [==============================] - 9s 613us/step - loss: 0.4572 - accuracy: 0.7827 - val_loss: 0.4554 - val_accuracy: 0.7842\n",
      "Epoch 27/50\n",
      "14450/14450 [==============================] - 9s 614us/step - loss: 0.4571 - accuracy: 0.7829 - val_loss: 0.4553 - val_accuracy: 0.7841\n",
      "Epoch 28/50\n",
      "14450/14450 [==============================] - 9s 624us/step - loss: 0.4571 - accuracy: 0.7829 - val_loss: 0.4552 - val_accuracy: 0.7842\n",
      "Epoch 29/50\n",
      "10978/14450 [=====================>........] - ETA: 1s - loss: 0.4572 - accuracy: 0.7831"
     ]
    }
   ],
   "source": [
    "#para scikit-learn: (samples,features)\n",
    "#test_input_T = test_input.T\n",
    "#X_train, X_test, y_train, y_test = train_test_split(test_input_T,test_labels,test_size=0.25,random_state=None)\n",
    "\n",
    "#ANN\n",
    "test1_model = models.Sequential()\n",
    "test1_model.add(layers.Dense(100,activation='relu',input_shape=(10,)))\n",
    "test1_model.add(layers.Dense(100,activation='relu'))\n",
    "#test1_model.add(layers.Dense(32,activation='relu'))\n",
    "#test1_model.add(layers.Dense(10,activation='relu'))\n",
    "test1_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "test1_model.compile(optimizer=optimizers.Adam(lr=0.0001),#RMSprop(lr=0.001),\n",
    "                    loss=losses.binary_crossentropy,\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "test1_model.summary()\n",
    "\n",
    "test1_model_history = test1_model.fit(X_train,\n",
    "                                      y_trainl,\n",
    "                                      epochs=50,\n",
    "                                      batch_size=32,\n",
    "                                      validation_data=(X_test,y_testl),\n",
    "                                      verbose=1)\n",
    "\n",
    "#plot\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(11,4.5))    \n",
    "\n",
    "results_dict = test1_model_history.history\n",
    "epochs = range(1,len(results_dict['accuracy'])+1)\n",
    "\n",
    "#accuracy\n",
    "acc_values = results_dict['accuracy']\n",
    "val_acc_values = results_dict['val_accuracy']\n",
    "    \n",
    "axs[0].plot(epochs,acc_values,color='black',label='train',linewidth=1.5,linestyle='-')\n",
    "axs[0].plot(epochs,val_acc_values,color='red',label='test',linewidth=1.5,linestyle='-')\n",
    "axs[0].set_xlabel('epochs')\n",
    "minorLocatorX = AutoMinorLocator()\n",
    "axs[0].xaxis.set_minor_locator(minorLocatorX)\n",
    "axs[0].set_ylabel('accuracy')\n",
    "axs[0].set_ylim([0.5,1.02])   \n",
    "minorLocatorY = AutoMinorLocator()\n",
    "axs[0].yaxis.set_minor_locator(minorLocatorY)\n",
    "axs[0].tick_params(which='major', length=6)\n",
    "axs[0].tick_params(which='minor', length=3, color='black')       \n",
    "axs[0].legend(loc='lower right')\n",
    "    \n",
    "#loss\n",
    "loss_values = results_dict['loss']\n",
    "val_loss_values = results_dict['val_loss']\n",
    "       \n",
    "axs[1].plot(epochs,loss_values,color='black',label='train',linewidth=1.5,linestyle='-')\n",
    "axs[1].plot(epochs,val_loss_values,color='red',label='test',linewidth=1.5,linestyle='-')\n",
    "axs[1].set_xlabel('epochs')\n",
    "minorLocatorX = AutoMinorLocator()\n",
    "axs[1].xaxis.set_minor_locator(minorLocatorX)   \n",
    "axs[1].set_ylabel('loss')\n",
    "minorLocatorY = AutoMinorLocator()\n",
    "axs[1].yaxis.set_minor_locator(minorLocatorY)\n",
    "axs[1].tick_params(which='major', length=6)\n",
    "axs[1].tick_params(which='minor', length=3, color='black')    \n",
    "axs[1].legend(loc='upper right')\n",
    "\n",
    "axs[0].set_title('Training and test accuracy after {} epochs: \\n {:.3f} (train), {:.3f} (validation)'\n",
    "                 .format(len(epochs),acc_values[-1],val_acc_values[-1]));\n",
    "\n",
    "axs[1].set_title('Training and test loss after {} epochs: \\n {:.3f} (train), {:.3f} (validation)'\n",
    "                 .format(len(epochs),loss_values[-1],val_loss_values[-1]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e354449",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
