{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5685f17d",
   "metadata": {},
   "source": [
    "# This notebook implements Deep learning techniques for a particle-in-halo classification framework. \n",
    "\n",
    "Reference with random forest: [ChJazhiel notebook](https://github.com/ChJazhiel/ML_ICF/blob/master/RF_Particles_z23.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90d76f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# workdirectory = '/home/jazhiel/ML_Notebooks/Cosmology_ML/'\n",
    "workdirectory = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9463edce",
   "metadata": {},
   "source": [
    "## Import our dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8611873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.00000000e+00  2.72242898e+13  1.13894322e+13 ... -1.00000000e+00\n",
      " -1.00000000e+00 -1.00000000e+00]\n",
      "289964\n"
     ]
    }
   ],
   "source": [
    "data_dict = np.load(workdirectory + 'OUTFILE1M.npz') #np.load('/path/to/nbody/outfile.npz')\n",
    "test_flags  = data_dict['test_flags'] ## not important\n",
    "test_hosts  = data_dict['test_hosts'] ### somewhat relevant\n",
    "test_mass   = data_dict['test_mass'] ## important\n",
    "test_labels = data_dict['test_labels'] ## important\n",
    "test_input  = data_dict['test_input'] ## very important\n",
    "#test_snid   = dict_data['test_snid']\n",
    "#test_labels = dict_data['test_labels']\n",
    "print(test_mass) ## Here I want to check how is the halo mass matrix composed of, the -1 means the halo \n",
    "#is not in our range of 10^12-10^13 M_sun\n",
    "print(np.sum(test_labels)) ## Here I want to check how many label \"1\" do we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294f585b",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e5683e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### here we create or 10 vector dataset, I wonder if by adding some other information the classification will be better\n",
    "### adding mass is not helpful, the classifier is perfect in that regard\n",
    "dr1 = pd.DataFrame(test_input[0], columns = ['dr1'])\n",
    "dr2 = pd.DataFrame(test_input[1], columns = ['dr2'])\n",
    "dr3 = pd.DataFrame(test_input[2], columns = ['dr3'])\n",
    "dr4 = pd.DataFrame(test_input[3], columns = ['dr4'])\n",
    "dr5 = pd.DataFrame(test_input[4], columns = ['dr5'])\n",
    "dr6 = pd.DataFrame(test_input[5], columns = ['dr6'])\n",
    "dr7 = pd.DataFrame(test_input[6], columns = ['dr7'])\n",
    "dr8 = pd.DataFrame(test_input[7], columns = ['dr8'])\n",
    "dr9 = pd.DataFrame(test_input[8], columns = ['dr9'])\n",
    "dr10 = pd.DataFrame(test_input[9], columns = ['dr10'])\n",
    "#mass = pd.DataFrame(test_mass, columns = ['Halo_Mass'])\n",
    "lbl = pd.DataFrame(test_labels, columns =['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b35048",
   "metadata": {},
   "source": [
    "## Select all features and create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a8ae1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dr1</th>\n",
       "      <th>dr2</th>\n",
       "      <th>dr3</th>\n",
       "      <th>dr4</th>\n",
       "      <th>dr5</th>\n",
       "      <th>dr6</th>\n",
       "      <th>dr7</th>\n",
       "      <th>dr8</th>\n",
       "      <th>dr9</th>\n",
       "      <th>dr10</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.209889</td>\n",
       "      <td>-0.187730</td>\n",
       "      <td>-0.169542</td>\n",
       "      <td>-0.155964</td>\n",
       "      <td>-0.100744</td>\n",
       "      <td>-0.049741</td>\n",
       "      <td>-0.011099</td>\n",
       "      <td>-0.010984</td>\n",
       "      <td>-0.002834</td>\n",
       "      <td>0.024089</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.364046</td>\n",
       "      <td>0.430008</td>\n",
       "      <td>0.453121</td>\n",
       "      <td>0.450021</td>\n",
       "      <td>0.374578</td>\n",
       "      <td>0.309706</td>\n",
       "      <td>0.240559</td>\n",
       "      <td>0.190503</td>\n",
       "      <td>0.174401</td>\n",
       "      <td>0.176335</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.311775</td>\n",
       "      <td>0.254511</td>\n",
       "      <td>0.227109</td>\n",
       "      <td>0.215286</td>\n",
       "      <td>0.148460</td>\n",
       "      <td>0.112097</td>\n",
       "      <td>0.090454</td>\n",
       "      <td>0.058546</td>\n",
       "      <td>0.035873</td>\n",
       "      <td>0.043613</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.033877</td>\n",
       "      <td>0.051836</td>\n",
       "      <td>0.065151</td>\n",
       "      <td>0.073930</td>\n",
       "      <td>0.100935</td>\n",
       "      <td>0.100271</td>\n",
       "      <td>0.094132</td>\n",
       "      <td>0.080007</td>\n",
       "      <td>0.059981</td>\n",
       "      <td>0.032160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.355428</td>\n",
       "      <td>-0.330448</td>\n",
       "      <td>-0.306125</td>\n",
       "      <td>-0.291701</td>\n",
       "      <td>-0.253399</td>\n",
       "      <td>-0.215256</td>\n",
       "      <td>-0.163749</td>\n",
       "      <td>-0.124680</td>\n",
       "      <td>-0.080408</td>\n",
       "      <td>-0.051999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>0.022223</td>\n",
       "      <td>0.034349</td>\n",
       "      <td>0.046298</td>\n",
       "      <td>0.047812</td>\n",
       "      <td>0.027945</td>\n",
       "      <td>0.018082</td>\n",
       "      <td>0.012005</td>\n",
       "      <td>0.015623</td>\n",
       "      <td>0.028762</td>\n",
       "      <td>0.036779</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>-0.178963</td>\n",
       "      <td>-0.188312</td>\n",
       "      <td>-0.189045</td>\n",
       "      <td>-0.187326</td>\n",
       "      <td>-0.182576</td>\n",
       "      <td>-0.170714</td>\n",
       "      <td>-0.155041</td>\n",
       "      <td>-0.143078</td>\n",
       "      <td>-0.136640</td>\n",
       "      <td>-0.120222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>-0.164632</td>\n",
       "      <td>-0.113120</td>\n",
       "      <td>-0.076089</td>\n",
       "      <td>-0.061724</td>\n",
       "      <td>0.009549</td>\n",
       "      <td>0.039809</td>\n",
       "      <td>0.057906</td>\n",
       "      <td>0.041327</td>\n",
       "      <td>0.010610</td>\n",
       "      <td>-0.020231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>-0.039698</td>\n",
       "      <td>0.063765</td>\n",
       "      <td>0.118363</td>\n",
       "      <td>0.140928</td>\n",
       "      <td>0.152761</td>\n",
       "      <td>0.125845</td>\n",
       "      <td>0.114529</td>\n",
       "      <td>0.113929</td>\n",
       "      <td>0.107155</td>\n",
       "      <td>0.098008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>0.153398</td>\n",
       "      <td>0.110778</td>\n",
       "      <td>0.080120</td>\n",
       "      <td>0.065841</td>\n",
       "      <td>0.043615</td>\n",
       "      <td>0.033935</td>\n",
       "      <td>0.012979</td>\n",
       "      <td>-0.002245</td>\n",
       "      <td>-0.008278</td>\n",
       "      <td>-0.021117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             dr1       dr2       dr3       dr4       dr5       dr6       dr7  \\\n",
       "0      -0.209889 -0.187730 -0.169542 -0.155964 -0.100744 -0.049741 -0.011099   \n",
       "1       0.364046  0.430008  0.453121  0.450021  0.374578  0.309706  0.240559   \n",
       "2       0.311775  0.254511  0.227109  0.215286  0.148460  0.112097  0.090454   \n",
       "3       0.033877  0.051836  0.065151  0.073930  0.100935  0.100271  0.094132   \n",
       "4      -0.355428 -0.330448 -0.306125 -0.291701 -0.253399 -0.215256 -0.163749   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "999995  0.022223  0.034349  0.046298  0.047812  0.027945  0.018082  0.012005   \n",
       "999996 -0.178963 -0.188312 -0.189045 -0.187326 -0.182576 -0.170714 -0.155041   \n",
       "999997 -0.164632 -0.113120 -0.076089 -0.061724  0.009549  0.039809  0.057906   \n",
       "999998 -0.039698  0.063765  0.118363  0.140928  0.152761  0.125845  0.114529   \n",
       "999999  0.153398  0.110778  0.080120  0.065841  0.043615  0.033935  0.012979   \n",
       "\n",
       "             dr8       dr9      dr10  labels  \n",
       "0      -0.010984 -0.002834  0.024089       0  \n",
       "1       0.190503  0.174401  0.176335       1  \n",
       "2       0.058546  0.035873  0.043613       1  \n",
       "3       0.080007  0.059981  0.032160       0  \n",
       "4      -0.124680 -0.080408 -0.051999       0  \n",
       "...          ...       ...       ...     ...  \n",
       "999995  0.015623  0.028762  0.036779       0  \n",
       "999996 -0.143078 -0.136640 -0.120222       0  \n",
       "999997  0.041327  0.010610 -0.020231       0  \n",
       "999998  0.113929  0.107155  0.098008       0  \n",
       "999999 -0.002245 -0.008278 -0.021117       0  \n",
       "\n",
       "[1000000 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([dr1, dr2, dr3, dr4, dr5, dr6, dr7, dr8, dr9, dr10, lbl], axis=1, ignore_index=False, sort=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ebe86a",
   "metadata": {},
   "source": [
    "## Here we select a dataframe consisting of evenly separated labels\n",
    "\n",
    "(I'm not sure if selecting all particles will impact in a different result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89d16555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dr1</th>\n",
       "      <th>dr2</th>\n",
       "      <th>dr3</th>\n",
       "      <th>dr4</th>\n",
       "      <th>dr5</th>\n",
       "      <th>dr6</th>\n",
       "      <th>dr7</th>\n",
       "      <th>dr8</th>\n",
       "      <th>dr9</th>\n",
       "      <th>dr10</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>852894</th>\n",
       "      <td>0.102846</td>\n",
       "      <td>0.084565</td>\n",
       "      <td>0.074973</td>\n",
       "      <td>0.072405</td>\n",
       "      <td>0.089686</td>\n",
       "      <td>0.103981</td>\n",
       "      <td>0.105024</td>\n",
       "      <td>0.085952</td>\n",
       "      <td>0.051139</td>\n",
       "      <td>0.039769</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446794</th>\n",
       "      <td>0.673512</td>\n",
       "      <td>0.456902</td>\n",
       "      <td>0.370605</td>\n",
       "      <td>0.340619</td>\n",
       "      <td>0.225556</td>\n",
       "      <td>0.161210</td>\n",
       "      <td>0.083929</td>\n",
       "      <td>0.038879</td>\n",
       "      <td>0.005992</td>\n",
       "      <td>-0.016802</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767258</th>\n",
       "      <td>0.356473</td>\n",
       "      <td>0.214281</td>\n",
       "      <td>0.158017</td>\n",
       "      <td>0.136651</td>\n",
       "      <td>0.072421</td>\n",
       "      <td>0.052794</td>\n",
       "      <td>0.044656</td>\n",
       "      <td>0.043945</td>\n",
       "      <td>0.042434</td>\n",
       "      <td>0.040661</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474997</th>\n",
       "      <td>0.257582</td>\n",
       "      <td>0.163283</td>\n",
       "      <td>0.141332</td>\n",
       "      <td>0.138210</td>\n",
       "      <td>0.134389</td>\n",
       "      <td>0.135707</td>\n",
       "      <td>0.122718</td>\n",
       "      <td>0.073848</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>-0.057583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711891</th>\n",
       "      <td>0.173705</td>\n",
       "      <td>0.160352</td>\n",
       "      <td>0.143946</td>\n",
       "      <td>0.133133</td>\n",
       "      <td>0.135115</td>\n",
       "      <td>0.120767</td>\n",
       "      <td>0.082296</td>\n",
       "      <td>0.065740</td>\n",
       "      <td>0.054758</td>\n",
       "      <td>0.036958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266780</th>\n",
       "      <td>-0.134234</td>\n",
       "      <td>-0.066986</td>\n",
       "      <td>-0.034929</td>\n",
       "      <td>-0.024988</td>\n",
       "      <td>0.026008</td>\n",
       "      <td>0.038451</td>\n",
       "      <td>0.046804</td>\n",
       "      <td>0.069830</td>\n",
       "      <td>0.095081</td>\n",
       "      <td>0.098712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230973</th>\n",
       "      <td>-0.069222</td>\n",
       "      <td>-0.060010</td>\n",
       "      <td>-0.053405</td>\n",
       "      <td>-0.046040</td>\n",
       "      <td>-0.026596</td>\n",
       "      <td>-0.012115</td>\n",
       "      <td>0.021917</td>\n",
       "      <td>0.034834</td>\n",
       "      <td>0.039080</td>\n",
       "      <td>0.026853</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272647</th>\n",
       "      <td>0.233213</td>\n",
       "      <td>0.170339</td>\n",
       "      <td>0.142273</td>\n",
       "      <td>0.132676</td>\n",
       "      <td>0.102715</td>\n",
       "      <td>0.079554</td>\n",
       "      <td>0.050270</td>\n",
       "      <td>0.018579</td>\n",
       "      <td>-0.020370</td>\n",
       "      <td>-0.047505</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850627</th>\n",
       "      <td>-0.182761</td>\n",
       "      <td>-0.068712</td>\n",
       "      <td>-0.004495</td>\n",
       "      <td>0.009333</td>\n",
       "      <td>0.053104</td>\n",
       "      <td>0.059387</td>\n",
       "      <td>0.051115</td>\n",
       "      <td>0.045354</td>\n",
       "      <td>0.049470</td>\n",
       "      <td>0.046791</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903156</th>\n",
       "      <td>0.373750</td>\n",
       "      <td>0.297725</td>\n",
       "      <td>0.273279</td>\n",
       "      <td>0.264274</td>\n",
       "      <td>0.233568</td>\n",
       "      <td>0.198450</td>\n",
       "      <td>0.158082</td>\n",
       "      <td>0.133869</td>\n",
       "      <td>0.114610</td>\n",
       "      <td>0.094727</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>578000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             dr1       dr2       dr3       dr4       dr5       dr6       dr7  \\\n",
       "852894  0.102846  0.084565  0.074973  0.072405  0.089686  0.103981  0.105024   \n",
       "446794  0.673512  0.456902  0.370605  0.340619  0.225556  0.161210  0.083929   \n",
       "767258  0.356473  0.214281  0.158017  0.136651  0.072421  0.052794  0.044656   \n",
       "474997  0.257582  0.163283  0.141332  0.138210  0.134389  0.135707  0.122718   \n",
       "711891  0.173705  0.160352  0.143946  0.133133  0.135115  0.120767  0.082296   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "266780 -0.134234 -0.066986 -0.034929 -0.024988  0.026008  0.038451  0.046804   \n",
       "230973 -0.069222 -0.060010 -0.053405 -0.046040 -0.026596 -0.012115  0.021917   \n",
       "272647  0.233213  0.170339  0.142273  0.132676  0.102715  0.079554  0.050270   \n",
       "850627 -0.182761 -0.068712 -0.004495  0.009333  0.053104  0.059387  0.051115   \n",
       "903156  0.373750  0.297725  0.273279  0.264274  0.233568  0.198450  0.158082   \n",
       "\n",
       "             dr8       dr9      dr10  labels  \n",
       "852894  0.085952  0.051139  0.039769       1  \n",
       "446794  0.038879  0.005992 -0.016802       1  \n",
       "767258  0.043945  0.042434  0.040661       1  \n",
       "474997  0.073848  0.002087 -0.057583       1  \n",
       "711891  0.065740  0.054758  0.036958       0  \n",
       "...          ...       ...       ...     ...  \n",
       "266780  0.069830  0.095081  0.098712       0  \n",
       "230973  0.034834  0.039080  0.026853       1  \n",
       "272647  0.018579 -0.020370 -0.047505       0  \n",
       "850627  0.045354  0.049470  0.046791       1  \n",
       "903156  0.133869  0.114610  0.094727       0  \n",
       "\n",
       "[578000 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sorting out the labels consisting in label '0' and label '1'\n",
    "## Then we sample them in order to not selecting them in a specific range or shape\n",
    "\n",
    "df_0 = df.sort_values('labels').head(710036).sample(289000)\n",
    "df_1 = df.sort_values('labels').tail(289964).sample(289000) \n",
    "df_1.labels.sum()\n",
    "df_r = pd.concat([df_0, df_1])\n",
    "#df_scaled = scaler.fit_transform(df_r.drop(['labels'], axis = 1))  \n",
    "#df_copy1 = pd.DataFrame(df_scaled, columns=['dr1', 'dr2', 'dr3', 'dr4', 'dr5', 'dr6', 'dr7', 'dr8', 'dr9', 'dr10'])\n",
    "\n",
    "shuffle_df = df_r.sample(frac = 1.0)\n",
    "#shuffle_df.insert(10, \"Model\", ['LC','SF']*14300, True)\n",
    "shuffle_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6945ae",
   "metadata": {},
   "source": [
    "## define a size for our traning dataset \n",
    "\n",
    "I think that for 500k + particles we can divide into train, test and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53e3070e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dr1</th>\n",
       "      <th>dr2</th>\n",
       "      <th>dr3</th>\n",
       "      <th>dr4</th>\n",
       "      <th>dr5</th>\n",
       "      <th>dr6</th>\n",
       "      <th>dr7</th>\n",
       "      <th>dr8</th>\n",
       "      <th>dr9</th>\n",
       "      <th>dr10</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>852894</th>\n",
       "      <td>0.102846</td>\n",
       "      <td>0.084565</td>\n",
       "      <td>0.074973</td>\n",
       "      <td>0.072405</td>\n",
       "      <td>0.089686</td>\n",
       "      <td>0.103981</td>\n",
       "      <td>0.105024</td>\n",
       "      <td>0.085952</td>\n",
       "      <td>0.051139</td>\n",
       "      <td>0.039769</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446794</th>\n",
       "      <td>0.673512</td>\n",
       "      <td>0.456902</td>\n",
       "      <td>0.370605</td>\n",
       "      <td>0.340619</td>\n",
       "      <td>0.225556</td>\n",
       "      <td>0.161210</td>\n",
       "      <td>0.083929</td>\n",
       "      <td>0.038879</td>\n",
       "      <td>0.005992</td>\n",
       "      <td>-0.016802</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767258</th>\n",
       "      <td>0.356473</td>\n",
       "      <td>0.214281</td>\n",
       "      <td>0.158017</td>\n",
       "      <td>0.136651</td>\n",
       "      <td>0.072421</td>\n",
       "      <td>0.052794</td>\n",
       "      <td>0.044656</td>\n",
       "      <td>0.043945</td>\n",
       "      <td>0.042434</td>\n",
       "      <td>0.040661</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474997</th>\n",
       "      <td>0.257582</td>\n",
       "      <td>0.163283</td>\n",
       "      <td>0.141332</td>\n",
       "      <td>0.138210</td>\n",
       "      <td>0.134389</td>\n",
       "      <td>0.135707</td>\n",
       "      <td>0.122718</td>\n",
       "      <td>0.073848</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>-0.057583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711891</th>\n",
       "      <td>0.173705</td>\n",
       "      <td>0.160352</td>\n",
       "      <td>0.143946</td>\n",
       "      <td>0.133133</td>\n",
       "      <td>0.135115</td>\n",
       "      <td>0.120767</td>\n",
       "      <td>0.082296</td>\n",
       "      <td>0.065740</td>\n",
       "      <td>0.054758</td>\n",
       "      <td>0.036958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268495</th>\n",
       "      <td>0.193962</td>\n",
       "      <td>0.233838</td>\n",
       "      <td>0.247723</td>\n",
       "      <td>0.250165</td>\n",
       "      <td>0.194097</td>\n",
       "      <td>0.158222</td>\n",
       "      <td>0.135334</td>\n",
       "      <td>0.106480</td>\n",
       "      <td>0.063084</td>\n",
       "      <td>0.027466</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599640</th>\n",
       "      <td>0.243180</td>\n",
       "      <td>0.210116</td>\n",
       "      <td>0.177020</td>\n",
       "      <td>0.155800</td>\n",
       "      <td>0.164132</td>\n",
       "      <td>0.167751</td>\n",
       "      <td>0.149791</td>\n",
       "      <td>0.129122</td>\n",
       "      <td>0.104378</td>\n",
       "      <td>0.090101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74199</th>\n",
       "      <td>-0.079473</td>\n",
       "      <td>-0.118908</td>\n",
       "      <td>-0.130251</td>\n",
       "      <td>-0.132316</td>\n",
       "      <td>-0.123047</td>\n",
       "      <td>-0.108568</td>\n",
       "      <td>-0.084090</td>\n",
       "      <td>-0.071873</td>\n",
       "      <td>-0.050527</td>\n",
       "      <td>-0.040226</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111717</th>\n",
       "      <td>0.263636</td>\n",
       "      <td>0.151838</td>\n",
       "      <td>0.113359</td>\n",
       "      <td>0.104937</td>\n",
       "      <td>0.030118</td>\n",
       "      <td>0.014838</td>\n",
       "      <td>0.023553</td>\n",
       "      <td>0.040797</td>\n",
       "      <td>0.057181</td>\n",
       "      <td>0.065337</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840834</th>\n",
       "      <td>0.271982</td>\n",
       "      <td>0.227724</td>\n",
       "      <td>0.184097</td>\n",
       "      <td>0.164222</td>\n",
       "      <td>0.109859</td>\n",
       "      <td>0.102721</td>\n",
       "      <td>0.098004</td>\n",
       "      <td>0.070959</td>\n",
       "      <td>0.048941</td>\n",
       "      <td>0.048742</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>462400 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             dr1       dr2       dr3       dr4       dr5       dr6       dr7  \\\n",
       "852894  0.102846  0.084565  0.074973  0.072405  0.089686  0.103981  0.105024   \n",
       "446794  0.673512  0.456902  0.370605  0.340619  0.225556  0.161210  0.083929   \n",
       "767258  0.356473  0.214281  0.158017  0.136651  0.072421  0.052794  0.044656   \n",
       "474997  0.257582  0.163283  0.141332  0.138210  0.134389  0.135707  0.122718   \n",
       "711891  0.173705  0.160352  0.143946  0.133133  0.135115  0.120767  0.082296   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "268495  0.193962  0.233838  0.247723  0.250165  0.194097  0.158222  0.135334   \n",
       "599640  0.243180  0.210116  0.177020  0.155800  0.164132  0.167751  0.149791   \n",
       "74199  -0.079473 -0.118908 -0.130251 -0.132316 -0.123047 -0.108568 -0.084090   \n",
       "111717  0.263636  0.151838  0.113359  0.104937  0.030118  0.014838  0.023553   \n",
       "840834  0.271982  0.227724  0.184097  0.164222  0.109859  0.102721  0.098004   \n",
       "\n",
       "             dr8       dr9      dr10  labels  \n",
       "852894  0.085952  0.051139  0.039769       1  \n",
       "446794  0.038879  0.005992 -0.016802       1  \n",
       "767258  0.043945  0.042434  0.040661       1  \n",
       "474997  0.073848  0.002087 -0.057583       1  \n",
       "711891  0.065740  0.054758  0.036958       0  \n",
       "...          ...       ...       ...     ...  \n",
       "268495  0.106480  0.063084  0.027466       1  \n",
       "599640  0.129122  0.104378  0.090101       0  \n",
       "74199  -0.071873 -0.050527 -0.040226       0  \n",
       "111717  0.040797  0.057181  0.065337       1  \n",
       "840834  0.070959  0.048941  0.048742       1  \n",
       "\n",
       "[462400 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a size for your train set \n",
    "train_size = int(0.8 * len(df_r))\n",
    "\n",
    "# Split your dataset \n",
    "train_set = shuffle_df[:train_size]\n",
    "test_set = shuffle_df[train_size:]\n",
    "\n",
    "train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea37a45e",
   "metadata": {},
   "source": [
    "## Select data, X for attributes, y for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcff1978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(462400, 10)\n"
     ]
    }
   ],
   "source": [
    "X = shuffle_df.drop(['labels'], axis = 1)\n",
    "ylabels = shuffle_df.labels\n",
    "#ymodel = shuffle_df.Model\n",
    "#ymodel = copy1.Model\n",
    "X_train = train_set.drop(['labels'], axis = 1)\n",
    "X_test = test_set.drop(['labels'], axis= 1)\n",
    "y_trainl = train_set.labels\n",
    "y_testl = test_set.labels\n",
    "#y_trainM = train_set.Model\n",
    "#y_testM = test_set.Model\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4b80d4",
   "metadata": {},
   "source": [
    "## For the Confusion matrix \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee69ca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### THIS CELL IS FOR CALCULATE THE CONFUSION MATRIX ####\n",
    "\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "    \n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4b75da",
   "metadata": {},
   "source": [
    "## Random forest with sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75046e03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning and Testing on raw data, all features \n",
      "\n",
      "Accuracy: 0.7839273356401384\n",
      "Random Forest accuracy for the 0 score: 0.78\n",
      "Random Forest accuracy for the 1 score: 0.79\n",
      "Random Forest accuracy for the 2 score: 0.78\n",
      "Random Forest Accuracy: 0.78 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "rf=RandomForestClassifier(n_estimators=100, max_depth=8, n_jobs=-1,\n",
    "                          criterion = 'entropy', class_weight='balanced')\n",
    "\n",
    "## n_jobs = -1 tells my computer to use all its cores, I have only 2, so it runs on 2 cores\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "rf.fit(X_train,y_trainl)\n",
    "\n",
    "ypred = rf.predict(X_test)\n",
    "#####\n",
    "\n",
    "print('Traning and Testing on raw data, all features \\n');\n",
    "#### Model accuracy\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_testl, ypred))\n",
    "\n",
    "for i, score_forest in enumerate(cross_val_score(rf, X, ylabels, cv = 3)):\n",
    "    print('Random Forest accuracy for the %d score: %0.2f' % (i, score_forest))\n",
    "score_forest=cross_val_score(rf, X, ylabels, cv=3)\n",
    "#score_tree\n",
    "cv_scores = []\n",
    "print(\"Random Forest Accuracy: %0.2f (+/- %0.2f)\" % (score_forest.mean(), score_forest.std() * 2 ))\n",
    "cv_score = score_forest.mean()\n",
    "cv_scores.append(cv_score)\n",
    "\n",
    "### We perform a cross validation score to see how accurate our decision tree is by \n",
    "### splitting the dataset into 10 folds for training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c5ab21",
   "metadata": {},
   "source": [
    "## Perceptron with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f21163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 22:52:37.139653: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-09 22:52:37.139670: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-09 22:52:37.139682: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (isidro-pc): /proc/driver/nvidia/version does not exist\n",
      "2022-05-09 22:52:37.139928: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/isidro/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n",
      "2022-05-09 22:52:37.215983: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               1100      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 11,301\n",
      "Trainable params: 11,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      " 1225/14450 [=>............................] - ETA: 7s - loss: 0.5117 - accuracy: 0.7649"
     ]
    }
   ],
   "source": [
    "#para scikit-learn: (samples,features)\n",
    "#test_input_T = test_input.T\n",
    "#X_train, X_test, y_train, y_test = train_test_split(test_input_T,test_labels,test_size=0.25,random_state=None)\n",
    "\n",
    "#ANN\n",
    "test1_model = models.Sequential()\n",
    "test1_model.add(layers.Dense(100,activation='relu',input_shape=(10,)))\n",
    "test1_model.add(layers.Dense(100,activation='relu'))\n",
    "#test1_model.add(layers.Dense(32,activation='relu'))\n",
    "#test1_model.add(layers.Dense(10,activation='relu'))\n",
    "test1_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "test1_model.compile(optimizer=optimizers.Adam(lr=0.0001),#RMSprop(lr=0.001),\n",
    "                    loss=losses.binary_crossentropy,\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "test1_model.summary()\n",
    "\n",
    "test1_model_history = test1_model.fit(X_train,\n",
    "                                      y_trainl,\n",
    "                                      epochs=50,\n",
    "                                      batch_size=32,\n",
    "                                      validation_data=(X_test,y_testl),\n",
    "                                      verbose=1)\n",
    "\n",
    "#plot\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(11,4.5))    \n",
    "\n",
    "results_dict = test1_model_history.history\n",
    "epochs = range(1,len(results_dict['accuracy'])+1)\n",
    "\n",
    "#accuracy\n",
    "acc_values = results_dict['accuracy']\n",
    "val_acc_values = results_dict['val_accuracy']\n",
    "    \n",
    "axs[0].plot(epochs,acc_values,color='black',label='train',linewidth=1.5,linestyle='-')\n",
    "axs[0].plot(epochs,val_acc_values,color='red',label='test',linewidth=1.5,linestyle='-')\n",
    "axs[0].set_xlabel('epochs')\n",
    "minorLocatorX = AutoMinorLocator()\n",
    "axs[0].xaxis.set_minor_locator(minorLocatorX)\n",
    "axs[0].set_ylabel('accuracy')\n",
    "axs[0].set_ylim([0.5,1.02])   \n",
    "minorLocatorY = AutoMinorLocator()\n",
    "axs[0].yaxis.set_minor_locator(minorLocatorY)\n",
    "axs[0].tick_params(which='major', length=6)\n",
    "axs[0].tick_params(which='minor', length=3, color='black')       \n",
    "axs[0].legend(loc='lower right')\n",
    "    \n",
    "#loss\n",
    "loss_values = results_dict['loss']\n",
    "val_loss_values = results_dict['val_loss']\n",
    "       \n",
    "axs[1].plot(epochs,loss_values,color='black',label='train',linewidth=1.5,linestyle='-')\n",
    "axs[1].plot(epochs,val_loss_values,color='red',label='test',linewidth=1.5,linestyle='-')\n",
    "axs[1].set_xlabel('epochs')\n",
    "minorLocatorX = AutoMinorLocator()\n",
    "axs[1].xaxis.set_minor_locator(minorLocatorX)   \n",
    "axs[1].set_ylabel('loss')\n",
    "minorLocatorY = AutoMinorLocator()\n",
    "axs[1].yaxis.set_minor_locator(minorLocatorY)\n",
    "axs[1].tick_params(which='major', length=6)\n",
    "axs[1].tick_params(which='minor', length=3, color='black')    \n",
    "axs[1].legend(loc='upper right')\n",
    "\n",
    "axs[0].set_title('Training and test accuracy after {} epochs: \\n {:.3f} (train), {:.3f} (validation)'\n",
    "                 .format(len(epochs),acc_values[-1],val_acc_values[-1]));\n",
    "\n",
    "axs[1].set_title('Training and test loss after {} epochs: \\n {:.3f} (train), {:.3f} (validation)'\n",
    "                 .format(len(epochs),loss_values[-1],val_loss_values[-1]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e354449",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
